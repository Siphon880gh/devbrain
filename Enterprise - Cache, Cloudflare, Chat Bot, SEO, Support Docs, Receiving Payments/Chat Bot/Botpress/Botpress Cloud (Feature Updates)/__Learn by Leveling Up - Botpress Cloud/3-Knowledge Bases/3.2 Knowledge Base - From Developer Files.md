Here we will have Chat bot respond to the user's question based on the knowledge bases library. There is a card called the Query Knowledge Bases that uses something called a Knowledge Agent. The knowledge agent uses an underlying model like ChatGPT but it's scoped to only the vector database that gets produced when you updated or add to the Knowledge Base tab. 

> [!note] Proof Knowledge Base is vectorized
> - "For your convenience, we express the storage quota of your vector database in gigabytes, but the actual unit being measured is the number of vectors contained in your bot’s knowledge base." - https://botpress.com/academy-lesson/vector-database-storage#:~:text=On%20Botpress%2C%20your%20knowledge%20base,queries%20with%20relevant%2C%20accurate%20information.
>  - ![[Pasted image 20250520193323.png]]
>


First let's add to our Knowledge Bases:
- Click blue button "New Knowledge Base" and name the new Knowledge Base as "Recipes":
![[Pasted image 20250520192303.png]]

At the top, click "Document" to upload documents:
![[Pasted image 20250520192516.png]]

Let's upload a recipe txt file to the Knowledge Base "Recipes":
```
Here’s a **classic Roman-style Spaghetti alla Carbonara** recipe — simple, authentic, and creamy *without* any cream.

---

### 🍝 **Spaghetti alla Carbonara (Authentic Recipe)**

#### ✅ Ingredients (Serves 2)

* **200g (7 oz) spaghetti**
* **100g (3.5 oz) guanciale** (or pancetta as a substitute)
* **2 large egg yolks** + **1 whole egg**
* **50g (1.75 oz) Pecorino Romano**, finely grated
* **Freshly ground black pepper**
* **Salt** (for pasta water)

---

#### 👨‍🍳 Instructions

1. **Boil the pasta water**

   * Bring a large pot of salted water to a boil.

2. **Prep the guanciale**

   * Cut guanciale into short strips or small cubes.
   * Place in a cold pan and cook over medium heat until golden and crisp (about 5–7 min). Turn off heat and leave it in the pan.

3. **Whisk the eggs and cheese**

   * In a bowl, whisk **2 yolks + 1 whole egg**.
   * Add **most of the grated Pecorino** (save some for garnish).
   * Add a good amount of black pepper and mix well. Set aside.

4. **Cook the pasta**

   * Add spaghetti to the boiling water and cook **1 minute short of al dente**.
   * Reserve **½ cup pasta water**, then drain the pasta.

5. **Combine**

   * Add hot pasta to the pan with guanciale (off heat).
   * Quickly stir to coat pasta in the fat.
   * Wait 30 seconds to cool slightly, then pour in the egg-cheese mixture while **tossing rapidly** to avoid scrambling the eggs.
   * Add a little **reserved pasta water** as needed to make a creamy, glossy sauce.

6. **Serve immediately**

   * Top with extra Pecorino and cracked pepper.

---

#### 🔥 Tips for Success

* **No cream** — the creaminess comes from emulsifying egg, cheese, and pasta water.
* **Guanciale > Pancetta > Bacon** (in order of authenticity).
* Stir constantly while adding the egg mixture to avoid curdling.
* Use **Pecorino Romano** (not Parmigiano) for true Roman flavor.

---

Let me know if you want a version with bacon or for a larger group!

```


> [!note] FYI - Visioning in Knowledge Bases
> If had you uploaded PDFs that don't have selectable text, screenshots, photos of documents, you would need to have the paid version of Botpress Cloud that can perform OCR and Vision processing:
> ![[Pasted image 20250520192837.png]]


---

With the knowledge base filled in, we would like the Chat Bot to be able to answer questions about recipes (without relying on ChatGPT's vast knowledge).

Desired - here we ask about a recipe that exists in the knowledge base:
![[Pasted image 20250520194004.png]]

Desired - here we ask specific questions about a recipe:
![[Pasted image 20250520194129.png]]

We should also test for cases when the information isn't in our knowledge base

Desired lack of knowledge response:
- Level 1 - Here we show that the Knowledge Base will only answer questions we have knowledge of. If the information is lacking in the knowledge base, it just ends the conversation:
- Level 2 in this document will implement the rest of the workflow so that it TELLS the user that the information is not in our knowledge.
  ![[Pasted image 20250520194332.png]]


---

## Level 1

We will have a knowledge agent that can answer questions about Carbonara recipe. It will lack recipe information for Fettuccine Alfredo, and therefore abruptly ends the conversation if asked.

We also build the foundational nodes for Knowledge Agent at Level 1

Workflow:
![[Pasted image 20250520212149.png]]

Nodes:
- Standard_3_2_1. Using Raw Input, asks user to enter their question, and then store that question as a variable `knowledgeAgentQuestion` . Then Query Knowledge Bases Card takes the question (from recalling `knowledgeAgentQuestion` , with specified Knowledge Bases, saves the answer (or lack of answer) to the variable KnowledgeAgentResponse.
- Standard_3_2_2_Success. Just a Text Card that echoes back the Knowledge Agent's response.

---

**Focusing on this node:**
![[Pasted image 20250520203154.png]]

Configure Raw Input Card (here called "knowledgeAgentQuestion"):
- We capture the user's question into a variable `knowledgeAgentQuestion` (so we can pass the variable into the Knowledge Agent)
- Have ON "Add transition to handle failure". If the option is not available, it's hidden under Advanced Configuration -> Advanced.
![[Pasted image 20250520195323.png]]


Configure Query Knowledge Bases Card
- Firstly, where to find the Query Knowledge Bases Card:
  ![[Pasted image 20250520195722.png]]
- Recall that the user's question was captured from Raw Input into the variable `knowledgeAgentQuestion`
- Referring to the below screenshot of the Query Knowledge Agent card:
	- We point the question to the variable that contains the question at `knowledgeAgentQuestion`
	- The Knowledge Agent will answer the user's question using AI scoped to only the vector databases (Your Knowledge Bases).
	- The answer gets saved to the variable `knowledgeAgentResponse` for later displaying.

> [!note] FYI: The pattern you may notice is that the Knowledge Agent never interacts with the Chat bot. Botpress designed some nodes with an eye towards separation of concerns - Knowledge Agent is only concerned about the question and the answer, and does not know about the Chat.
> 


- Looks like:	
	![[Pasted image 20250520201752.png]]


Let's zoom out to the workflow:
![[Pasted image 20250520212149.png]]

If the Inputting stage fails, user gets a message "Failed" because of the Text Card at node Standard_3_2_2_Fail1

If the inputting stage passes, the user's inputted question passes into the Knowledge Agent, then its answer saves to the variable `knowledgeAgentResponse`. Then a subsequent node displays `knowledgeAgentResponse` to user's chat, regardless if it was a success or a failure. A failure would be if the knowledge agent can't find anything in the Knowledge Base to answer the user's question.

Setup the subsequent nodes. You should be skilled enough to set them up without much guidance.

After that's done, let's test the Chat Bot asking a question it knows (about Carbonara):
![[Pasted image 20250520194129.png]]


Works fine! 

Now let's ask a question the Knowledge Bases do not contain:
![[Pasted image 20250520194332.png]]

The inputting did not fail, so it didn't display "Failed" to the user. It continues to ask the Knowledge Agent which will have no answer. See "No valid answer found" status text in the Chat Bot. At Level 2 in the next section, we will handle that "No valid answer found" by displaying a message to the user. We will have two branches for the Knowledge Agent for valid answer and no valid answer.

---

## Level 2

When the knowledge agent fails because the question doesn't have an answer in the knowledge base, it'll just return null. A Text Card that just receives null would just not send anything to the Chat bot and that's by design by Botpress, because it doesn't make sense to send an empty message in chat. Instead - as seen in the previous screenshot above, the chat bot seem to end abruptly but that's because the next node is the End node.

If you inspect the variables (panel underneath workflows), you'll see the knowledgeAgentResponse is Empty (aka null under the hood's code):

![[Pasted image 20250520205930.png]]

We will add two Expressions (remember learning them from [[2.09 Multiple Choice - Other freetype using expression and raw input]]?). See that there are two Expressions labeled Falsy and Truthy outletted from the Knowledge Agent:
![[Pasted image 20250520220948.png]]

**Overview:**
The top expression is when Knowledge Agent can't provide a valid answer so under the hood it's an Empty or null, which evaluates to falsy; it'll transition to showing the message "Failed". Instead of creating an entire new node with the text card displaying "Failed", we just connect it back to the other "Failed" message.

The bottom expression is when Knowledge Agent has answered with words and under the hood, any string that has characters will evaluate to truthy, so it evaluates to truthy;  it'll transition to showing the stored answer in `knowledgeAgentResponse` to the user's chat.

**Creating the expressions:**

Recall you add an Expression card by searching for "expression":
![[Pasted image 20250520211236.png]]

Configure top expression to be falsy based on the answer variable that may be empty/null or may contain words:
- Note if you get locked out of manually entering into the fields, refer to [[Annoying UI Quirk - Expression Card wants to be AI generated]]
![[Pasted image 20250520231249.png]]

Configure bottom expression to continue when the answer is truthy (has characters):
![[Pasted image 20250520231549.png]]

Now test the Chat Bot. Ask it something it shouldn't know. It'll tell you it failed:
![[Pasted image 20250520231741.png]]

## More customer friendly

Instead of messaging back that it failed, you could explain more clearly to the customer that we just don't have information on that particular topic:
```
I'm sorry, but I don't have information on that particular topic at the moment. Our current knowledge base doesn't cover it, but we're always working to improve. If this is important, I recommend reaching out to our team directly for further help
```

The Chat would've looked like:
![[Pasted image 20250520232156.png]]

And because we don't fall back on the general "Failed" message, we create a separate node that apologizes. We made sure that Falsy expression outlets to that node:
![[Pasted image 20250520232326.png]]

We will not cover how to implement this more appropriate message. You should be able to do it yourself following the above screenshot. HOWEVER:

We will in the next lesson fall back to ChatGPT's wide knowledge base when our own knowledge base can't answer the user's question.