Aka Get Started

Download atÂ [https://lmstudio.ai/](https://lmstudio.ai/)

It will ask to download a model if first using ~5gb:
![[Pasted image 20250207041415.png]]

After downloading, it appears as if you can start chatting right away, but not. Check the top to see if still loading:
![[Pasted image 20250207041433.png]]

 You can just start asking questions:
 ![[Pasted image 20250207041609.png]]

---

Too slow?

You can ask perplexity.ai:
```
With a 16GB MacBook Pro on a M1 chip, what's an appropriate model for LM Studio?
```

And you can ask for better settings with ChatGOT:
```
Im using DeepSeek R1 Distill Qwen 7B on LM Studio. How to improve performance. These are the settings 
- Context Length
- GPU Offload
- CPU Thread Pool Size
- Evaluation Batch Size
- RoPE Frequence Base
- RoPE Frequeence Scale
- Keep MOdel in Memory
- Try mmap()
- Seed
- Flash Attention
- K Cache Quantization Type
- V Cache Quantization Type
```


![[Pasted image 20250207041852.png]]

Last resort is get a better computer.