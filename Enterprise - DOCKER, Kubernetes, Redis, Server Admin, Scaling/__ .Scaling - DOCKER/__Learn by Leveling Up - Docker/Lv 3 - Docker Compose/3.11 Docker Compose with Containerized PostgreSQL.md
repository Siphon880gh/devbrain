Setup the project files:

docker-compose.yml:
```
version: '3.8'

services:
  postgres:
    image: postgres:latest
    container_name: ${DB_HOST}
    ports:
      - "${DB_PORT}:${DB_PORT}"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_DB=${DB_NAME}
    env_file:
      - .env

  express_server:
    build: .
    restart: always
    ports:
      - "3000:3000"
    env_file:
      - .env
    depends_on:
      - postgres

volumes:
  postgres_data:
```

^ Explanation: postgres image gets installed from the remote Hub (unless you have `docker build` built an image exactly named and tagged "postgres:latest" - which is a no-no). Remember that docker compose will look for such an image name on your system's docker and if it does not find it, then it proceeds to search the online Hub. 

^ Btw: This is how you mapped .env variables to docker compose variables!



.env:
```
DB_USER=postgres
DB_PASSWORD=postgres
DB_HOST=postgres
DB_PORT=5432
DB_NAME=docker_tests
```

^ postgres container at the Hub has default username password: postgres/postgres.



app.js:
```
const express = require('express');
const { Pool } = require('pg');
require('dotenv').config();

const app = express();
const port = 3000;

// PostgreSQL connection configuration
const pool = new Pool({
  user: process.env.DB_USER,
  host: process.env.DB_HOST,
  database: process.env.DB_NAME,
  password: process.env.DB_PASSWORD,
  port: process.env.DB_PORT,
});

// Middleware
app.use(express.json());

// Test database connection
app.get('/test-db', async (req, res) => {
  try {
    const result = await pool.query('SELECT NOW()');
    res.json({ 
      message: 'Database connection successful',
      timestamp: result.rows[0].now 
    });
  } catch (err) {
    console.error('Database connection error:', err);
    res.status(500).json({ 
      error: 'Database connection failed',
      details: err.message 
    });
  }
});

// Example route to create a table
app.get('/setup', async (req, res) => {
  try {
    await pool.query(`
      CREATE TABLE IF NOT EXISTS users (
        id SERIAL PRIMARY KEY,
        name VARCHAR(100),
        email VARCHAR(100) UNIQUE,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      );
    `);
    res.json({ message: 'Table created successfully' });
  } catch (err) {
    console.error('Setup error:', err);
    res.status(500).json({ 
      error: 'Setup failed',
      details: err.message 
    });
  }
});

// Example route to add a user
app.post('/users', async (req, res) => {
  const { name, email } = req.body;
  try {
    const result = await pool.query(
      'INSERT INTO users (name, email) VALUES ($1, $2) RETURNING *',
      [name, email]
    );
    res.json(result.rows[0]);
  } catch (err) {
    console.error('Error adding user:', err);
    res.status(500).json({ 
      error: 'Failed to add user',
      details: err.message 
    });
  }
});

// Example route to get all users
app.get('/users', async (req, res) => {
  try {
    const result = await pool.query('SELECT * FROM users');
    res.json(result.rows);
  } catch (err) {
    console.error('Error fetching users:', err);
    res.status(500).json({ 
      error: 'Failed to fetch users',
      details: err.message 
    });
  }
});

// Start server
app.listen(port, () => {
  console.log(`Server running on port ${port}`);
});
```

^ Explanation on database name: If the database doesn't exist, postgreSQL will create it, so that's not a concern. The database name can be anything from the .env file. We chose to name it `docker_tests`.

^ Explanation on pg: We are using NodeJS pg package to connect to PostgreSQL server on the Docker network (created by running docker compose). When running from the perspective of he containerized app.js, it has access to hostname postgres. Recall that docker compose automatically assigns hostnames to services in docker-compose that have port numbers, and the hostname is basically the container name.

^ Explanation: Because the PostgreSQL is a separate instance from your local machine, you'll need to seed the table from this dockerize script. So there's a /setup endpoint. Then we will insert new users using POST /users .... Then we will confirm this affected the postgreSQL database by getting all users with /users endpoint. This will be done in the next major section where we run the docker-compose.yml.


Dockerfile (Standard for Express NodeJS app):
```
# Use the specific NodeJS base image (bundled in Debian)
FROM node:18

# Set the working directory in the container.
# All below commands will work from working directory.
WORKDIR /usr/src/app

# Copy the package.json file to the container
COPY package*.json ./

# Install the NodeJS packages
RUN npm install

# Copy your application files (if any)
COPY . .

# Specify the command to run your application (optional, depends on your use case)
CMD ["node", "app.js"]

# Expose the port the application runs on
EXPOSE 3000
```

.dockerignore:
```
.DS_Store
node_modules
package-lock.json
__pycache__
*.pyc
.env
```


package.json:
```
{
    "dependencies": {
        "express": "4.21.2",
        "pg": "^8.13.3",
        "dotenv": "^16.4.7"
    }
}
```


----


Now run docker composer in foreground mode (in case we need to see any errors):
```
docker compose up
```

To test this, in another terminal:

1. See if connection to database is successful
```
curl http://localhost:3000/test-db
```

2. Create the users table:
```
curl http://localhost:3000/setup
```

3. Add a user:
```
curl -X POST -H "Content-Type: application/json" -d '{"name":"John Doe","email":"john@example.com"}' http://localhost:3000/users
```

4. Get all users (see if the user you added appears):
```
curl http://localhost:3000/users
```


5. Shutdown the containers with:
```
docker compose down
```


5. Run back up the containers:
```
docker compose up
```

6. And get all users to see if the data persisted beyond ephemeral container restarts (it should because of the volume mounting):
```
curl http://localhost:3000/users
```