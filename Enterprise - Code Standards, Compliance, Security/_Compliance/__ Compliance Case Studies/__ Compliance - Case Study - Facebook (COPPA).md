**Facebook (and Instagram)** officially restrict access to users **under the age of 13**, aligning with **COPPA** requirements. However, Facebook’s enforcement history includes notable failures that led to **major privacy fines and scrutiny**, though less about direct COPPA violations and more about **general data privacy** and **misrepresentation**.

Let’s expand the table to include **Facebook** and see how it compares:

---

### **COPPA & Child Privacy Compliance Comparison: YouTube vs TikTok vs Facebook**

|**Category**|**YouTube**|**TikTok (formerly Musical.ly)**|**Facebook**|
|---|---|---|---|
|**Initial Violation**|Collected data from users on child-directed videos without parental consent|Allowed children under 13 to create accounts and share public content without parental consent|Allegedly collected data from children under 13 who lied about their age; also failed to delete underage accounts promptly|
|**Regulation Breached**|COPPA|COPPA|COPPA (arguably), GDPR (confirmed), FTC Act|
|**Year of Enforcement**|2019|2019|Ongoing issues; major FTC fine in 2019; further scrutiny in 2021–2023|
|**Fine**|$170 million (FTC + NY AG)|$5.7 million (FTC)|$5 billion (2019 FTC for privacy violations — broad, not strictly COPPA); Meta fined €1.2B under GDPR in 2023|
|**What Triggered Enforcement**|Serving targeted ads to kids on child-directed content|Children under 13 could sign up, post public content, and receive DMs|Kids signing up by lying about their age; Facebook failed to detect/remove accounts; broader privacy missteps|
|**Key Compliance Failures**|- No parental consent- Behavioral ads on kids’ videos|- No parental consent- Public accounts for kids- Weak age gates|- Inadequate age verification- Delayed removal of under-13 accounts- Repeated privacy lapses|
|**Post-Enforcement Actions**|- Mandatory content labeling- Feature lockdown on kids’ videos- YouTube Kids emphasis|- TikTok for Younger Users- Walled garden, no uploading- Age segmentation|- Stronger AI for age detection- Improved content filters- Tools for parental oversight (especially on Instagram)- Working on youth-only platforms (e.g., Messenger Kids)|
|**Current Kids Compliance Model**|Label-based video categorization and restrictions|Separate app logic for under-13 users|Users must be 13+ to join; Messenger Kids exists separately with strict parental controls|
|**Impact on Users/Creators**|Monetization and engagement limits on “kids” content|Younger users can’t interact freely; creators lose under-13 reach|Youth accounts under tighter scrutiny; reputational damage|
|**Lesson for Startups**|Must build compliance into creator tools and ad systems|Need hard enforcement of age gates and reduced functionality for minors|Don’t rely on self-declared age; build detection and moderation pipelines proactively|

---

### ⚠️ Key Note on Facebook:

- Facebook has been accused of **not promptly removing under-13 accounts** even when reported.
- While not directly penalized under COPPA, its **GDPR violations** and **FTC settlement** are the largest privacy-related fines ever issued.
- Meta has since invested in **Messenger Kids**, age estimation tools, and **supervised experiences** for teens — showing how even massive platforms must **pivot to restore trust**.
