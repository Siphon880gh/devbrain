Required knowledge:
- Know what are AI Agents

AI Agents in many AI apps are specialized workers that automate parts of your development workflow. They run in the background, respond to triggers, transform files, and follow structured instructions. Firstly, review what AI Agents are in the broader context of AI apps:
[[_PRIMER - AI Agents - What are they]]

---

## **AI Agents in Cursor:**
- No multi-agent: Cannot work in coordination with other AI Agents. One AI Agent is not aware of another AI Agent's state.
- No agent roles and names: In some agentic technologies, there are agents that play roles, like a summary agent or a QA agent. There might also be an identity (you can name an AI Agent) so you can instruct Agent 2 to wait for Agent 1 to finish before performing X.
- Trigger and Tooling are not matured: 
	- Telling it to fire the prompt when a file exists won't be sufficient. You have to explain it to access shell terminal to loop until a file exists, taking advantage of AI agent waiting on shell commands. There is no matured file structure toolset.
	- AI cannot change the model (eg. Opus 4.5 vs 4o) or mode (Local, Working Tree, Cloud). There is no matured Cursor toolset.

---

## **Agents Work With Local Files and GitHub**

Cursor AI agent can work:

* Directly in your **local environment**
* Inside an online **GitHub repo**
* Or both

Because it has tool knowledge to work on local file structure or with online Github repo. This flexibility supports solo developers, teams, automation pipelines, and mixed workflows. Wherever your code lives, agents can operate on it.

Local:
![[Pasted image 20251214070619.png]]

Github repo:
- Requirement: Your local github repo must have an origin pointing to an online repo
![[Pasted image 20251214070531.png]]

---

## **Agents Run in Parallel — but Not in Coordination**

Cursor allows multiple agents to run simultaneously, each performing its own transformation. As they finish, effects simply appear—no manual babysitting required.

### **Parallel ≠ Collaborative**

Agents do **not** communicate with each other. There's no built-in mechanism like:

* *"Agent 2, wait until Agent 1 finishes this file."*
* *"This text is already translated—don't rewrite it."*

Each agent independently processes whatever falls inside its rules.

### **Example: When Agents Collide**

* **Translator Agent** converts English → Spanish
* **Personality Agent** rewrites tone

If Personality Agent expects English, it may distort the Spanish result. If their order flips, the tone rewrite might get lost during translation. Agents trigger when applicable—they don't negotiate order.

### **Example: Can Agent 1 Trigger Agent 2?**

You might want:

* **Schema Agent** generates `schema.json`
* **Client Agent** generates API client code based on the schema

Can Schema Agent tell Client Agent "I'm done, your turn"? **No.** There's no direct agent-to-agent messaging or signaling in Cursor.

However, you can achieve this indirectly—instruct Client Agent to wait for `schema.json` to exist before proceeding. This "file gate" pattern (covered in [DIY Coordination Techniques](#diy-coordination-techniques)) lets you simulate sequential handoffs without actual agent communication.

---

## **How Agents Respond to Triggers**

So how do agents know when to act? They activate in response to **triggers**—events that tell the agent "it's time."

### **Common Trigger Types**
* **Chat messages** — Messages in Cursor's chat matching the agent's scope. 
	- Cursor agents can be instructed—via a project-level `agents.md`—to respond to **specific keyphrases or invocation patterns in a prompt**, effectively routing a request to a predefined behavior or sub-prompt.
	- Cursor, Windsurf, Copilot, etc all have agreed to read a root level **Agents.md** for such instructions

### **Pseudo Trigger Types**
* **File changes** — Save, create, or modify files matching patterns (e.g., `*.md`, `src/**/*.ts`)
* **Pattern matching** — Content inside a file matching specific rules or keywords

Cursor AI cannot handle file changes and pattern matches natively as of Dec 2025. In other words, Cursor agents **cannot natively react to file system events**, such as a file being created or modified, in the way a watcher, CI system, or workflow engine can.

To simulate file-based triggers, you must **procedurally instruct the agent** to run shell commands in a loop—e.g., polling every ~50ms—to check for file existence or changes, then interpret the shell output once the condition is met. In other words, you’re leveraging the agent’s ability to execute shell commands and reason over their output, not declaring a true “when A changes, run B” rule

---

## **Checkpoints for Human in the Loop Can Give You Control**

Worried an agent might push changes too far? Build **checkpoints** into the workflow.

A checkpoint is a pause where the agent stops, shows what it's done, and waits for approval before continuing. This lets you:

* Review each step
* Approve or revise
* Avoid unintended large-scale changes
* Maintain confidence in the process

You can always insert these "green-light moments" rather than one-shotting a full workflow.

---

## **Guided Automation Using Markdown Prompt Files**

Create multi-step automation by dropping **Markdown (.md) prompt files** into a folder, then tell the agent:

> "Follow the prompts in this folder in order."

The agent will:

1. Read each markdown file as an instruction
2. Execute steps sequentially
3. Apply them to specified files
4. Use checkpoints if included

This builds complex workflows without custom scripts—just give the agent a playbook.

**Examples:**

* Multi-step refactors
* Codebase cleanup workflows
* Linting + tone rewrite + documentation sequences
* Standardized project setup pipelines

### **A Note on Multi-Agent Execution**

When multiple agents run simultaneously, there is **no intelligent orchestration**. Cursor doesn't dynamically coordinate agents, resolve conflicts, or optimize execution order.

Any prioritization is based on simplistic heuristics—not "smart" scheduling that analyzes your workflow.

**Takeaway:** If agent order matters, design it yourself—chain prompts, use checkpoints, or run agents sequentially.

### **DIY Coordination Techniques**

Since Cursor won't coordinate agents for you, here are workarounds:

#### **1. File Existence as a Gate**

Have one agent wait for a file another agent creates:

* **Prompt 1:** "Generate the API schema and save to `schema.json`."
* **Prompt 2:** "Wait until `schema.json` exists, then generate client code based on it."

The second agent effectively "blocks" until the first agent's output appears.

#### **2. Shared State File for Pseudo-Parallel Coordination**

Use a shared state file like `cursor-agent-state.json`:

1. Both agents check if the file exists—if not, create it with initial flags
2. **Agent A** performs its task, then sets `"taskA_done": true`
3. **Agent B** is instructed: "When `taskA_done` is true, proceed"

```json
{
  "taskA_done": false,
  "taskB_done": false,
  "data_validated": false
}
```

Each agent reads the file, checks its flag, acts accordingly, and updates its flag when finished.

---

## **Summary**

In Cursor AI, think of AI agents as your multitasking little assistants. They can run in parallel, working on different tasks simultaneously, whether you're connecting them to a GitHub repository or having them operate on your local files.

One of the neat features is that you're not locked into a "one-shot" approach. You can set up checkpoints—points where the agent pauses and waits for your review before continuing. This gives you the peace of mind to make sure everything's on track.

You can also automate things by placing a series of prompts in markdown files inside a folder. The agent can then follow these prompts one by one in order, creating a kind of orchestrated workflow that still has checkpoints if you want them. So in a nutshell, you get a flexible, safe, and pretty smart way to run your AI workflows exactly the way you like.