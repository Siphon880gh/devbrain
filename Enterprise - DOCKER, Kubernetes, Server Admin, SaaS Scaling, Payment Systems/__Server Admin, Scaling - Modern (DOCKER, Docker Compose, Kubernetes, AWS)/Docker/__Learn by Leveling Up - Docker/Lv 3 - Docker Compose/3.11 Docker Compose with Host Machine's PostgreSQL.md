
Requirement: Have PostgreSQL installed locally on your computer and have it running in the background.

Let’s create some entries in PostgreSQL then have the dockerized express server return the contents of a PostgreSQL table in the web browser.

Create “docker_tests” database in PostgreSQL with a table called “test” whose schema is
id serial primary
my_key text

^ Note we are not using “key” for column because that’s a reserved keyword in PostgreSQL

Insert a row with the my_key text “Hello world!”

There are various ways to do this including psql shell, or executing your own backend code in pythonjs/nodejs/php/etc, or simply using pgAdmin4 which has a nice GUI.

You can run this query to perform all the above:
```
CREATE TABLE test (  
    id SERIAL PRIMARY KEY,  
    my_key TEXT NOT NULL  
);  
INSERT INTO test (my_key) VALUES ('Hello world!');  
SELECT * from test;
```

If using pgAdmin4:
Open Query Tool by right clicking on the database → Query Tool
![[Pasted image 20250304032418.png]]

---

Once you know that docker_tests → test → row with my_key column text “Hello world” exists on your computer’s PostgreSQL database server, let’s continue to the express script.

Create app.js:
```
const express = require('express');  
const { Pool } = require('pg');  
  
const app = express();  
const PORT = 3000;  
  
// Create a new pool using the connection details  
const pool = new Pool({  
    user: 'root',  
    password: '', // Set empty string for passwordless connection  
    host: 'localhost', // This is the service name in docker-compose  
    port: 5432,  
    database: 'docker_tests'  
  });  
  
app.get('/', async (req, res) => {  
  try {  
    const result = await pool.query('SELECT * FROM public.test');  
    res.json(result.rows);  
  } catch (err) {  
    console.error('Error executing query', err.stack);  
    res.status(500).json({ error: 'Internal server error' });  
  }  
});  
  
app.listen(PORT, () => {  
  console.log(`Server running on port ${PORT}`);  
});
```

Adjust your username and password for your PostgreSQL local server.

Then test the script directly:
```
node app.js
```

Visit `http://localhost:3000`  in the web browser. You should see:
```
[{"id":1,"my_key":"Hello world!"}]
```

Or, you see:
![[Pasted image 20250304032514.png]]

The reason why we are testing the node js script directly is because postgresql and nodejs dockerized is very particular for it to work, so we want to make sure the authentication and data flows without docker first

---

Now let’s add docker compose with dockerfile files:

.dockerignore:
```
.DS_Store  
node_modules  
package-lock.json  
__pycache__  
*.pyc  
.env
```

docker-compose.yml:
```
version: '3.8'  
  
services:  
  express_server:  
    build: .  
    restart: always  
    ports:  
      - "3000:3000"
```

Dockerfile (Standard for Express NodeJS app):
```
# Use the specific NodeJS base image (bundled in Debian)  
FROM node:18  
  
# Set the working directory in the container.  
# All below commands will work from working directory.  
WORKDIR /usr/src/app  
  
# Copy the package.json file to the container  
COPY package*.json ./  
  
# Install the NodeJS packages  
RUN npm install  
  
# Copy your application files (if any)  
COPY . .  
  
# Specify the command to run your application (optional, depends on your use case)  
CMD ["node", "app.js"]  
  
# Expose the port the application runs on  
EXPOSE 3000
```

package.json:
```
{  
    "dependencies": {  
        "express": "4.21.2",  
        "pg": "^8.13.3"  
    }  
}
```

Modify app.js’s host:
```
    host: 'host.docker.internal', // This will connect to your host machine's PostgreSQL
```

Now run docker composer in foreground mode (in case we need to see any errors):
```
docker compose up
```

Visit web browser: `[http://localhost:3000/](http://localhost:3000/)`

You should see your host postgresql row!

---

**Bonus #1**

We should make the host in app.js polymorphic:
```
    host: process.env.hostDockerInternal || 'localhost', // This will connect to your host machine's PostgreSQL
```

Add to docker-compose.yml such that:
```
version: '3.8'  
  
services:  
  express_server:  
    build: .  
    restart: always  
    ports:  
      - "3000:3000"  
    environment:  
      - hostDockerInternal=host.docker.internal
```

So if you run `node app.js`  directly, host would be “localhost” because the environmental variable won’t exist.

And if you ran the docker compose, then the docker-compose has set the environmental variable, so docker will see the hostname as “host.docker.internal” and successfully connects back to the host machine for postgresql

When you run the docker compose, add `--build` flag so it won't use the old cache:
```
docker compose up --build
```

---

**Bonus #2**

We should have the credentials and database information (besides host) as environmental variables. Hint: You can create an .env file and docker-composer.yml can refer to a `env_file`.